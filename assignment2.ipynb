{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SENTENCES ', 'MEANING', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
       "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
       "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17',\n",
       "       'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21',\n",
       "       'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25',\n",
       "       'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29',\n",
       "       'Unnamed: 30', 'Unnamed: 31'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('parallel-corpus.xlsx')\n",
    "df.head(2)\n",
    "df.columns\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCES</th>\n",
       "      <th>MEANING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I communicate with my parents?</td>\n",
       "      <td>میں اپنے والدین سے کیسے بات کروں ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I make friends?’</td>\n",
       "      <td>میں دوست کیسے بنائوں ؟</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SENTENCES                              MEANING\n",
       "0  How can I communicate with my parents?  میں اپنے والدین سے کیسے بات کروں ؟\n",
       "1                How can I make friends?’              میں دوست کیسے بنائوں ؟"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4','Unnamed: 5', 'Unnamed: 6', \n",
    "         'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9','Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
    "         'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17',\n",
    "         'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21',\n",
    "         'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25',\n",
    "         'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29',\n",
    "         'Unnamed: 30', 'Unnamed: 31'], axis = 1, inplace = True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCES      44\n",
      "MEANING       546\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I communicate with my parents?</td>\n",
       "      <td>میں اپنے والدین سے کیسے بات کروں ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I make friends?’</td>\n",
       "      <td>میں دوست کیسے بنائوں ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do I get so sad?’</td>\n",
       "      <td>میں اتنا اداس کیوں ہوں؟.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you’ve asked yourself such questions, you’r...</td>\n",
       "      <td>اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Depending on where you’ve turned for guidance,...</td>\n",
       "      <td>اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0             How can I communicate with my parents?   \n",
       "1                           How can I make friends?’   \n",
       "2                              Why do I get so sad?’   \n",
       "3  If you’ve asked yourself such questions, you’r...   \n",
       "4  Depending on where you’ve turned for guidance,...   \n",
       "\n",
       "                                                Urdu  \n",
       "0                 میں اپنے والدین سے کیسے بات کروں ؟  \n",
       "1                             میں دوست کیسے بنائوں ؟  \n",
       "2                           میں اتنا اداس کیوں ہوں؟.  \n",
       "3  اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...  \n",
       "4   اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.dropna(inplace=True)\n",
    "# Clean the dataset by keeping only the relevant columns: 'SENTENCES' (English) and 'MEANING' (Urdu)\n",
    "df_cleaned = df[['SENTENCES ', 'MEANING']].dropna()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "df_cleaned.columns = ['English', 'Urdu']\n",
    "\n",
    "# Display cleaned data\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCES</th>\n",
       "      <th>MEANING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I communicate with my parents?</td>\n",
       "      <td>میں اپنے والدین سے کیسے بات کروں ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I make friends?’</td>\n",
       "      <td>میں دوست کیسے بنائوں ؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do I get so sad?’</td>\n",
       "      <td>میں اتنا اداس کیوں ہوں؟.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you’ve asked yourself such questions, you’r...</td>\n",
       "      <td>اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Depending on where you’ve turned for guidance,...</td>\n",
       "      <td>اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          SENTENCES   \\\n",
       "0             How can I communicate with my parents?   \n",
       "1                           How can I make friends?’   \n",
       "2                              Why do I get so sad?’   \n",
       "3  If you’ve asked yourself such questions, you’r...   \n",
       "4  Depending on where you’ve turned for guidance,...   \n",
       "\n",
       "                                             MEANING  \n",
       "0                 میں اپنے والدین سے کیسے بات کروں ؟  \n",
       "1                             میں دوست کیسے بنائوں ؟  \n",
       "2                           میں اتنا اداس کیوں ہوں؟.  \n",
       "3  اگر آپ نے اپنے آپ سے ایسے سوالات کیے ہیں، تو آ...  \n",
       "4   اس بات پر منحصر ہے کہ آپ رہنمائی کے لیے کہاں ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21323, 20) (21323, 20) (2370, 20) (2370, 20) (5924, 20) (5924, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_VOCAB_SIZE = 10000  # Limit the vocabulary size\n",
    "MAX_SEQUENCE_LENGTH = 20  # Max length of sentences (after padding)\n",
    "\n",
    "# Tokenizer for English and Urdu\n",
    "eng_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "urdu_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "\n",
    "# Ensure that all data in the 'English' and 'Urdu' columns are strings\n",
    "df_cleaned['English'] = df_cleaned['English'].astype(str)\n",
    "df_cleaned['Urdu'] = df_cleaned['Urdu'].astype(str)\n",
    "\n",
    "# Now, retry tokenization\n",
    "eng_tokenizer.fit_on_texts(df_cleaned['English'])\n",
    "urdu_tokenizer.fit_on_texts(df_cleaned['Urdu'])\n",
    "# Convert the text into sequences of integers\n",
    "eng_sequences = eng_tokenizer.texts_to_sequences(df_cleaned['English'])\n",
    "urdu_sequences = urdu_tokenizer.texts_to_sequences(df_cleaned['Urdu'])\n",
    "\n",
    "# Pad the sequences to ensure uniform input size\n",
    "eng_padded = pad_sequences(eng_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "urdu_padded = pad_sequences(urdu_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# Split into training, validation, and test sets (80%, 10%, 10%)\n",
    "eng_train, eng_test, urdu_train, urdu_test = train_test_split(eng_padded, urdu_padded, test_size=0.2, random_state=42)\n",
    "eng_train, eng_val, urdu_train, urdu_val = train_test_split(eng_train, urdu_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Displaying the shape of the data\n",
    "print(eng_train.shape, urdu_train.shape, eng_val.shape, urdu_val.shape, eng_test.shape, urdu_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aquib Javed\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 128\n",
    "rnn_units = 256\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=embedding_dim, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(SimpleRNN(rnn_units, return_sequences=True))\n",
    "model.add(Dense(MAX_VOCAB_SIZE, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 221ms/step - accuracy: 0.4754 - loss: 4.3913 - val_accuracy: 0.5071 - val_loss: 3.4502\n",
      "Epoch 2/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 222ms/step - accuracy: 0.5100 - loss: 3.3233 - val_accuracy: 0.5229 - val_loss: 3.2806\n",
      "Epoch 3/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 236ms/step - accuracy: 0.5349 - loss: 3.0430 - val_accuracy: 0.5307 - val_loss: 3.1786\n",
      "Epoch 4/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 245ms/step - accuracy: 0.5412 - loss: 2.8959 - val_accuracy: 0.5363 - val_loss: 3.1228\n",
      "Epoch 5/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 222ms/step - accuracy: 0.5480 - loss: 2.7578 - val_accuracy: 0.5401 - val_loss: 3.0835\n",
      "Epoch 6/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 227ms/step - accuracy: 0.5524 - loss: 2.6481 - val_accuracy: 0.5429 - val_loss: 3.0653\n",
      "Epoch 7/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 219ms/step - accuracy: 0.5632 - loss: 2.5170 - val_accuracy: 0.5460 - val_loss: 3.0544\n",
      "Epoch 8/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 212ms/step - accuracy: 0.5739 - loss: 2.3969 - val_accuracy: 0.5478 - val_loss: 3.0536\n",
      "Epoch 9/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 208ms/step - accuracy: 0.5820 - loss: 2.3097 - val_accuracy: 0.5497 - val_loss: 3.0675\n",
      "Epoch 10/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 210ms/step - accuracy: 0.5900 - loss: 2.2217 - val_accuracy: 0.5496 - val_loss: 3.0754\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(eng_train, urdu_train, \n",
    "                    epochs=10, \n",
    "                    validation_data=(eng_val, urdu_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m predicted_sequence \u001b[38;5;241m=\u001b[39m predictions[i]\n\u001b[0;32m     11\u001b[0m actual_sequence \u001b[38;5;241m=\u001b[39m urdu_test[i]\n\u001b[1;32m---> 13\u001b[0m predicted_sentence \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43murdu_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m actual_sentence \u001b[38;5;241m=\u001b[39m sequence_to_text(urdu_tokenizer, actual_sequence)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnglish: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_text(eng_tokenizer,\u001b[38;5;250m \u001b[39meng_test[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[90], line 7\u001b[0m, in \u001b[0;36msequence_to_text\u001b[1;34m(tokenizer, sequences)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msequence_to_text\u001b[39m(tokenizer, sequences):\n\u001b[0;32m      6\u001b[0m     reverse_word_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mreversed\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([reverse_word_map\u001b[38;5;241m.\u001b[39mget(i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sequences])\n",
      "Cell \u001b[1;32mIn[90], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msequence_to_text\u001b[39m(tokenizer, sequences):\n\u001b[0;32m      6\u001b[0m     reverse_word_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mreversed\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mreverse_word_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sequences])\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "# Predict translations for the test set\n",
    "predictions = model.predict(eng_test)\n",
    "\n",
    "# Convert predictions from sequences back to words\n",
    "def sequence_to_text(tokenizer, sequences):\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    return \" \".join([reverse_word_map.get(i, '') for i in sequences])\n",
    "\n",
    "for i in range(5):  # Check the first 5 examples\n",
    "    predicted_sequence = predictions[i]\n",
    "    actual_sequence = urdu_test[i]\n",
    "\n",
    "    predicted_sentence = sequence_to_text(urdu_tokenizer, predicted_sequence)\n",
    "    actual_sentence = sequence_to_text(urdu_tokenizer, actual_sequence)\n",
    "\n",
    "    print(f\"English: {sequence_to_text(eng_tokenizer, eng_test[i])}\")\n",
    "    print(f\"Predicted Urdu: {predicted_sentence}\")\n",
    "    print(f\"Actual Urdu: {actual_sentence}\")\n",
    "    print(f\"BLEU Score: {sentence_bleu([actual_sentence.split()], predicted_sentence.split())}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
